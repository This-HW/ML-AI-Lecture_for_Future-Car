{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝이 발전하면서 여러가지로 세분화 되었다.\n",
    "\n",
    "Deep learning    \n",
    "-> CNN : 이미지 처리에 특화 (Converusion Neural Network)    \n",
    "Deep learing     \n",
    "-> RNN : 자연어 처리 (Recursive Neural Network)    \n",
    "(자연어는 - 앞에 있는 단어에 뒤에 있는 단어에 영향을 끼친다.)\n",
    "\n",
    "이렇게 두가지 알고리즘이 대표적인데, 다양한 알고리즘이 탄생하였고 지금도 생겨나고 있다.\n",
    "\n",
    "- - -\n",
    "지금도 계속 알고리즘이 생겨나고 있다.\n",
    "이미지 처리도 지금은 CNN보다 좋은 알고리즘으로 GNN 등이 나타나고 있다.\n",
    "이미지 처리를 잘 하기 위해서는 꼭 OpenCV를 같이 공부/사용 해야한다.\n",
    "OpenCv는 이미지 처리에 특화 된 라이브러리\n",
    "\n",
    "- - -\n",
    "이번엔 CNN을 사용해서 MNIST를 학습시켜보자.\n",
    "\n",
    "지금까지 우리가 한 학습은 Fully connected 네트워크이다. (모든 노드들이 연결되어 있었다.)    \n",
    "CNN 또한 뒤쪽에 FC 단계가 있다. 하지만 CNN의 중요한 특징은 FC 앞쪽에 있는 새로운 계층들이다.    \n",
    "\n",
    "CNN의 앞 부분은,    \n",
    "이미지 전체를 학습하는 것이 아니라 이미지를 잘게 쪼개서, 각 부분들을 학습한다.    \n",
    "그 잘게 쪼개진 이미지들을 학습하는 과정에서 이미지의 여러 ___특징___들이 학습된다.    \n",
    "\n",
    "잘게 쪼개진 이미지들의 용량이 커버리면 전체 용량이 너무 커져버린다.\n",
    "때문에 크기를 줄여줘야 원할한 학습이 가능해진다.    \n",
    "\n",
    "- - -\n",
    "## CNN\n",
    "\n",
    "### Filter\n",
    "필터의 크기는 내가 마음대로 설정 할 수 있지만 Depth는 원본 이미지(3)와 같아야한다. -> 원본 이미지와 매칭해야 되기 때문    \n",
    "Filter값을 정하고 Stride를 정하면 원본 이미지와 계산되어 몇개의 특징을 Node가 도출될지 계산된다.    \n",
    "\n",
    "### Stride\n",
    "Stride는 Image의 크기와 Filter값에 의해 가능한 숫자가 달라진다. (Default = 1) \n",
    "> ex>    \n",
    "크기가 7 * 7 * 3 인 이미지가 있다. (depth가 3인 이유 : 이미지는 ( R, G, B ) 3개의 값이 1 pixel을 구성하기 때문)    \n",
    "크기가 3 * 3 * 3 인 필터를 적용한다면, stride가 ~가 가능하다.    \n",
    "Stride가 Default인 1이라고 가정하면, \n",
    "    (image)7 * 7 * 3 -(filter : 3 * 3 * 3)-> (image)5 * 5 * 3 가 된다.\n",
    "\n",
    "이렇게 필터를 한단계 더 적용하게 되면 이미지 크기가 3 * 3 * 3이 되는데, 이는 크기가 너무 작아서 특징을 추출하기 어려워진다.\n",
    "그래서 __Padding__이 등장했다.\n",
    "\n",
    "### Padding\n",
    "\n",
    "\n",
    "\n",
    "그리고 이러한 특징들이 적용된 필터들을 하나의 계층에서도 여러개 만들 수 있다는 것이다.    \n",
    "그렇게 되면 점점 더 많은 필터들이 중첩되기 시작한다.\n",
    "> ex>\n",
    "첫 이미지    CONV, ReLU    Layer 1    \n",
    " 32x32x3   --(5x5x3, 6)--> 28x28x6\n",
    "\n",
    "\n",
    "이런식으로 진행되면 최종적으로,\n",
    "이미지의 크기는 줄어들지만 훨씬 더 많은 특징들을 학습 하게 된다.\n",
    "\n",
    "### multi filter\n",
    "여러개의 필터를 적용함으로써, 한 layer에서도 여러개의 필터를 적용 할 수 있다.\n",
    "덕분에 Depth 가 점점 더 깊어지게 된다.\n",
    "\n",
    "### Pooling (Max pooling)\n",
    "이건 특징을 추출할수록 이미지의 크기가 너무 커져서, 특징은 유지하며 이미지 크기를 줄이는 단계이다.\n",
    "여기는 필터와 비슷한 개념인 커널을 사용한다.\n",
    "커널이 필터와 같이 stride값에 따라, 이미지를 부분 부분으로 자르면서 가장 큰 값의 특징을 추출한다.\n",
    "그 덕분에 커널의 크기와 Stride 값에 따라 이미지의 특징을 잘 유지하면서도 이미지의 크기를 줄인 이미지를 만들 수 있다.\n",
    "\n",
    "Pooling은 이미지 크기를 조정 하고 싶을 때, 언제든 사용 할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 사용하는 이미지는 (이미지개수, 가로픽셀수, 세로픽셀수, color)\n",
    "# (1, 3, 3, 1) -> 이미지 한개, 3x3크기, 1->gray scale\n",
    "\n",
    "# image = np.array([[1],[2],[3]]) # 각각의 grayscale값을 한 행에 만들었다.\n",
    "\n",
    "# image = np.array([[1],[2],[3]],\n",
    "#                  [[4],[5],[6]],\n",
    "#                  [[7],[8],[9]]) # 숫자들은 grayscale의 값을 의미(임의값대입함), 그리고 3x3행열로 이미지 구현\n",
    "\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                 [[4],[5],[6]],\n",
    "                 [[7],[8],[9]]]], dtype=np.float64) # 이미지가 한개이기에 하나로 묶어준다. + 머신러닝은 실수형만 가능하다.\n",
    "# print(image.shape)\n",
    "\n",
    "# 필터에 대한 정보 (필터 가로픽셀, 필터 세로픽셀, color, 필터개수)\n",
    "# (2, 2, 1, 1)\n",
    "\n",
    "weight = np.array([[[[1]],[[1]]],\n",
    "                  [[[1]],[[1]]]], dtype=np.float64) # 1차원의 값을 가지고, 2x2의 크기를 가지는 필터를 1개 만들었다.\n",
    "# print(weight.shape)\n",
    "\n",
    "# stride = 1\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding = \"VALID\")\n",
    "# padding =\"VALID\"는 패딩이 없다는 뜻이다.\n",
    "print(conv2d.shape) # -> (1, 2, 2, 1) 이 나온다.\n",
    "# activation map에 1차원의 값을 갖고, 2x2의 크기로 1개의 필터가 있다는 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 CNN이 어떻게 이루어지는지 기본적인 원리를 알아보았다.    \n",
    "이제 MNIST를 CNN으로 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(1, 26, 26, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## MNIST 이미지를 이용해서 Convolution layer를 처리하자.\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# plt.imshow(mnist.train.images[0].reshape(28,28), cmap = \"Greys\")   자료의 첫번째 이미지를 28x28로 변환해서 표현한다.\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## 사용하는 이미지는 (이미지개수, 가로픽셀수, 세로픽셀수, color)\n",
    "img = mnist.train.images[0].reshape(1, 28, 28, 1) # -> 1차원 이미지를 Convolution을 수행 할 수 있는 4차원으로 바꾼 것.\n",
    "\n",
    "## 필터에 대한 정보 (필터가로픽셀, 필터세로픽셀, color, 필터개수)\n",
    "w = tf.Variable(tf.random_normal([3, 3, 1, 5]), name = \"filter1\")\n",
    "conv2d = tf.nn.conv2d(img, w, strides=[1,1,1,1], padding=\"VALID\") # strid가 가로1, 세로1이고, pading은 사용하지 않는다.\n",
    "# print(conv2d.shape) # -> (1, 26, 26, 5)가 잘 나온다.\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(conv2d)\n",
    "\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(sess.run(conv2d).shape)  # => (1, 26, 26, 5) 6가지 색의 26x26짜리 이미지가 1개 있다.\n",
    "# 이 이미지를 5개의 이미지, depth=1로 바꾸어 입력 할 수 있도록 변환한다.\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3) # 출력된 자료를 입력 할 수 있도록 축을 바꾼다.\n",
    "\n",
    "# plt.imshow(conv2d_img[0].reshape(26,26), cmap = \"Greys\")   #자료의 첫번째 필터의 이미지를 28x28로 변환해서 표현한다.\n",
    "plt.imshow(conv2d_img[1].reshape(26,26), cmap = \"Greys\")   #자료의 두번째 필터의 이미지를 28x28로 변환해서 표현한다.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 13, 13, 32)\n"
     ]
    }
   ],
   "source": [
    "## MNIST with CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## data loading, training data set, test data set\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "## placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32) # 처음에는 단순히 784개의 데이터를 입력받는다.\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32) # 10개의 결과값이 있다.\n",
    "\n",
    "## convolution layer\n",
    "# 기존의 input데이터를 이용해서 학습에 필요한 새로운 이미지를 만든다.\n",
    "## 사용하는 이미지는 (이미지개수, 가로픽셀수, 세로픽셀수, color)\n",
    "x_img = tf.reshape(X, [-1, 28, 28, 1]) # -1 : (행의 개수는) 너가 계산해  => 여기에서는 -1을 55000으로 계산 할 것이다.\n",
    "# 28x28의 이미지 색은 1개\n",
    "# 4차원이 아니면 Convolution 계산을 할 수 없다.\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32]), name=\"filter1\") # 필터를 랜던값으로 만든다.\n",
    "# 3x3의 이미지 크기, color-depth=1, 필터 32개\n",
    "\n",
    "L1 = tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding=\"VALID\") # 레이어를 만드는데, 스트라이드는 1, 패딩은 없다.\n",
    "# 이 결과로 L1에는 1개의 이미지로 32개의 이미지를 만들어낸다.\n",
    "L1 = tf.nn.relu(L1) # 만들어진 이미지들에 RELU 알고리즘을 적용한다.\n",
    "\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                   padding=\"VALID\") # 2x2 필터크기로 맥스풀링 한다. strides=2, Polling: X이다.\n",
    "print(L1.shape) # <- (?, 13, 13, 32)\n",
    "# 들어오는 이미지가 몇장인지 모르기에 ?로 표현되는데, 여기에서는 55000이다.\n",
    "# 이미지 크기는 13x13이고, 32 종류의 필터가 적용되어 있다. (각 이미지가 32종류가 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 Convolution Layer가 완성되었다.    \n",
    "하나의 이미지를 Convolution layer를 통해 다량의 이미지로 변환 추출하였고,    \n",
    "이러한 층을 반복 한 후,    \n",
    "최종 결과물로 얻은 이미지를 FC Layer에 입력으로 사용한다. (Fully Connected => 기존의 딥러닝)    \n",
    "- - -\n",
    "우리는 시간이 부족하기에, Convolution Layer를 위의 한개만 사용하고, 바로 FC Layer와 연결해보자.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "cost 값은 0.3269276022911072\n",
      "cost 값은 0.22774378955364227\n",
      "cost 값은 0.1718302220106125\n",
      "cost 값은 0.15598654747009277\n",
      "cost 값은 0.13899478316307068\n",
      "cost 값은 0.13315244019031525\n",
      "cost 값은 0.12538127601146698\n",
      "cost 값은 0.08300194889307022\n",
      "cost 값은 0.10085374116897583\n",
      "cost 값은 0.08333919197320938\n",
      "cost 값은 0.07923911511898041\n",
      "cost 값은 0.08413144946098328\n",
      "cost 값은 0.08823198080062866\n",
      "cost 값은 0.0917210504412651\n",
      "cost 값은 0.08804626762866974\n",
      "cost 값은 0.06992312520742416\n",
      "cost 값은 0.0604717954993248\n",
      "\n",
      "CNN\n",
      "correct rate : 0.968999981880188\n"
     ]
    }
   ],
   "source": [
    "# 얻은 이미지를 FC Layer에 활용\n",
    "L1 = tf.reshape(L1,[-1, 13*13*32]) # Convolution layer를 거치면서 이미지 수가 확 늘어났다.\n",
    "\n",
    "\n",
    "# dense layer\n",
    "## Weight & bias\n",
    "W1 = tf.get_variable(\"weight1\", shape = ([784,256]),\n",
    "                initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name = \"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, rate=0.3) # Drop out 실행\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape = ([256,512]),\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]), name = \"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate=0.3)  # Drop out 실행\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape = ([512,10]),\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name = \"bias3\")\n",
    "\n",
    "\n",
    "## Hypothesis\n",
    "logit = tf.matmul(layer2, W3) + b3  # 마지막 layer은 Drop out을 실행하지 않았다.\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "\n",
    "## cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "\n",
    "## train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "## Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "## 학습\n",
    "train_epoch = 50 # 학습을 횟수\n",
    "batch_size = 100 # 데이터를 나눠서 학습하는 것\n",
    "\n",
    "for step in range(train_epoch) :    \n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size) # 여기에서는 550이다.\n",
    "    cost_val=0\n",
    "    \n",
    "    for i in range(num_of_iter) :\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) # mnist에서는 배치크기에 따라 데이터들을 자동으로 만들어주는 함수가 있다.\n",
    "        \n",
    "        tmp_train, cost_val = sess.run([train, cost],\n",
    "                                      feed_dict = {X: batch_x, Y : batch_y})\n",
    "\n",
    "    if step % 3 == 0:\n",
    "        print(\"cost 값은 {}\".format(cost_val))\n",
    "        \n",
    "## 정확도 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"\\nCNN\\ncorrect rate : {}\".format(sess.run(accuracy, feed_dict={X: batch_x, Y : batch_y})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

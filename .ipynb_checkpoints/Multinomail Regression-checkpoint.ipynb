{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial classification\n",
    "\n",
    "\n",
    "\n",
    "### 원리\n",
    ">간단하게 설명하자면 Logistic Regression 여러개를 중첩해서 어디에 속하는지 구하는 것이다.    \n",
    "다만 Sigmoid 함수를 Softmax로 바꾸면 된다.    \n",
    "Sigmoid는 입력된 값이 어디에 속하는지 0, 1로 나누어 주주는 반면,    \n",
    "Softmax 함수는 입력된 값이 어떤 범위에 속할지 총합을 1로 한 확률을 구하는 것이다.    \n",
    "\n",
    ">이를 위해 H function이 바뀌어야 한다.    \n",
    "그리고 H fucntion이 바뀌면 Cost function 또한 따라 바뀌어야 한다.    \n",
    "\n",
    ">추가적으로 Y축은 각각의 Label로써 문자로 되어있는데, 이를 숫자로 바꾸어야지 계산을 할 수 있다.    \n",
    "이를 위한 표현법이 One hot encoding이다.    \n",
    "왜 1, 2, 3으로 표현이 되지 않는가?    \n",
    "왜냐하면 Hypothesis의 Output값의 포맷이 Lable의 수 만큼의 열로써 가지고 있는 Matrix로 나오기 때문이다.    \n",
    "\n",
    "Multinomial Regression은 이미 데이터 전처리가 되어있는 Mnist로 수행하겠다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0      cost :  12.587029\n",
      "step :  300      cost :  0.71954864\n",
      "step :  600      cost :  0.5529004\n",
      "step :  900      cost :  0.4968357\n",
      "step :  1200      cost :  0.46768048\n",
      "step :  1500      cost :  0.44591382\n",
      "step :  1800      cost :  0.42713353\n",
      "step :  2100      cost :  0.41019028\n",
      "step :  2400      cost :  0.39464906\n",
      "step :  2700      cost :  0.38027015\n",
      "step :  3000      cost :  0.36689073\n",
      "\n",
      "테스트 값 : [10, 8, 9, 4]\n",
      "각각의 카테고리에 속할 확률 :  [[6.9186312e-01 3.0768076e-01 4.5612347e-04]]\n",
      "One-hot-encoding으로 표현하면 :  [0]\n"
     ]
    }
   ],
   "source": [
    "## Multinomial Classificaton\n",
    "## Logistic 여러개를 모아놓은 multinomial classificaton을 구현하자.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set, test data set\n",
    "x_data = [[10, 7, 8, 5],\n",
    "         [8, 8, 9, 4],\n",
    "         [7, 8, 2, 3],\n",
    "         [6, 3, 9, 3],\n",
    "         [7, 5, 7, 4],\n",
    "         [3, 5, 6, 2],\n",
    "         [2, 4, 3, 1]]\n",
    "# y_data = [[\"A\"], [\"A\"], [\"B\"], [\"B\"], [\"B\"], [\"C\"], [\"C\"]] # 이렇게 해야 하지만 문자는 학습에 사용 할 수 없다.\n",
    "y_data = [[1,0,0], [1,0,0], [0,1,0], [0,1,0], [0,1,0], [0,0,1], [0,0,1]] # 이 때문에 원 핫 인코딩 방식으로 A, B, C를 표현한다.\n",
    "\n",
    "\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape = [None, 4], dtype = tf.float32) # 입력값의 경우 4개가 입력되기에 4개를 입력한다.\n",
    "Y = tf.placeholder(shape = [None, 3], dtype = tf.float32) # one-hot encoding으로 만든 컬럼의 수가 Y값이 되기에 3을 입력한다.\n",
    "\n",
    "\n",
    "# 3. Weight & Bias\n",
    "W = tf.Variable(tf.random_normal([4, 3]), name = \"weight\") # Logistic이 3개이기에 [4, 3]이 된다. \n",
    "# 4는 입력값을 받는 w 개수, 3은 그러한 logistic 함수가 3개가 있기 때문이다.\n",
    "b = tf.Variable(tf.random_normal([3]), name = \"bias\") # Logistic이 3개이기에 bias가 3개가 된다.\n",
    "\n",
    "\n",
    "# 4. Hypothesis\n",
    "logits = tf.matmul(X, W) + b\n",
    "H = tf.nn.softmax(logits) # 여러개의 logistic을 받는 fucntion은 softmax 함수이다.\n",
    "\n",
    "\n",
    "# 5. Cost fucntion\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels = Y))\n",
    "\n",
    "\n",
    "############################################\n",
    "# 여기부터는 logistic regression과 동일하다.\n",
    "## 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "## 7. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "## 8. training 학습 실행\n",
    "for step in range(3001):\n",
    "    tmp_train, cost_val = sess.run([train, cost], feed_dict = {X:x_data, Y:y_data})\n",
    "    \n",
    "    if step % 300 == 0 :\n",
    "        print(\"step : \", step,\"     cost : \", cost_val)\n",
    "        \n",
    "        \n",
    "## 9. prediction\n",
    "# 이번에는 accuracy를 측정하기 전에 prediction을 먼저 해보자\n",
    "\n",
    "print()\n",
    "print(\"테스트 값 : [10, 8, 9, 4]\")\n",
    "print(\"각각의 카테고리에 속할 확률 : \",sess.run(H, feed_dict={X:[[10, 8, 9, 4]]}))\n",
    "print(\"One-hot-encoding으로 표현하면 : \", sess.run(tf.argmax(sess.run(H, feed_dict={X:[[10, 8, 9, 4]]}), 1) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 predict결과를 보면 A학점일 확률이 가장 높다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "## 9. accuracy (정확도 측정)\n",
    "predict = tf.argmax(H, axis=1)\n",
    "# argmax는 각각의 속성 중에서 어떤 확률이 제일 높은지 알아내는 함수\n",
    "# axis = 1은 열 방향으로 계산을 하라는 뜻이다. 우리의 데이터는 행 방향이다.\n",
    "# + axis = 0은 행 방향으로 계산을 한다.\n",
    "\n",
    "# ????\n",
    "# print(\"predict :{}\".format())\n",
    "\n",
    "correct = tf.equal(predict, tf.argmax(Y, 1)) # axis는 생략되었다. axis = 1  => 1\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32)) # reduce_mean : 평균내는 함수, cast : 형변환 함수\n",
    "# correct가 tru false로 떨어지기에 형전환을 해 주어야 한다.\n",
    "\n",
    "\n",
    "# test 데이터가 없기에, Training데이터를 이용해 accuracy를 구한다.\n",
    "# 실제로는 test 데이터를 넣어야 한다.\n",
    "print(\"\\n정확도 : {}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))\n",
    "# Training데이터를 넣었기 때문에 Accuracy가 1이 나왔다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내일은 오늘 배운 내용을 바탕으로 Deep-learning을 학습 할 것이다.    \n",
    "그 중에서도 이미지 분석을 하는 Mnist를 할 예정이다.    \n",
    "\n",
    "그 중에서도 CNN알고리즘을 이용해 공부 할 예정이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

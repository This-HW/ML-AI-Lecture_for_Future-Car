# 3일차

-----

## Deep Learning

### 등장배경

> 기존의 Machine Learning(중에서도 Logistic)으로 AND 연산과 OR 연산은 가능했지만, __XOR연산__은 구현이 불가능했다.    
>
> 그러던 중 1969년, MIT Marvin Minsky 박사(전세계 AI 최고 권위자 중 한명)가 하나의 퍼셉트론는 XOR연산을 절대 구현할 수 없다고 말하며 퍼셉트론이 여러개(Multi layer) 있어야 구현할 수 있다고 말했다. 하지만 학습 방법이 너무 어려워서 지구상 누구도 학습이 불가능하다고 말했다.  그 말로 인해, 이후 AI는 침체기에 진입한다.
>
> 1974, Paul Werbos가 한개의 층을 여러개로 나누어서 학습을 시킬 수 있다는 __Backpropagation__ 제안했지만, 학회의 반응이 좋지 않았다.  1982년에 다시 말했지만 또 반응이 없었다.
>
> 1986년, Hinton박사가 Backpropagation이 가능하다는 것을 공언 해 주면서 AI가 다시 각광받기 시작하고, 연구가 다시 시작됩니다.
>
> 이후 Backpropagation이 layer가 많아질 경우 학습이 잘 되지 않는다는 것을 발견하고 AI와 다른 다양한 이론(SVM, Random Forest, etc)들이 등장하기 시작합니다.
>
> 캐나다에서 CIFAR를 설립하며, 전세계 AI 연구가들을 불러들여 연구를 시작했는데 그 중에는, 1987년 이주한 Hinton교수도 포함되었다. 그로부터 10년 후, 기존의 Backpropagation 방법이 잘 되지 않았던 이유를 2가지 발견하였다. 
>
> 1. 초기값 (w, b) 세팅 불량. 
> 2. Layer 수의 부족
>
> 이 두가지 문제를 해결하며 AI 연구는 다시 활성화 되기 시작했고, Deep Nets, __Deep Learing__으로 __Rebranding__ 후 전세계적인 인기를 가져오게 되었다. ___~~사실 예전부터 있던 것~~___



### 개념

> Deep Learning의 원리는 하나의 로지스틱에서 나온 결과값이 다음 로지스틱의 인풋값으로 들어가는 것이다. 기존의 ML에서는 불가능했지만, Deep Learning에서는 Layer(Perceptron)이 두개 이상이여서 이전 Layer의 결과값을 다음 Layer의 인풋값으로 넣을 수가 있었다.
>
> 이처럼, 층을 2개 이상으로 만들 수 있기 때문에 XOR문제도 자연스럽게 해결이 되었다.
>
> 뒤에서 배울 XOR 문제에서는 1st Layer에서는 Logistic Function을 2개, 2nd Layer에서는 Logistic Function을 1개 넣어서 학습 시킬 예정이지만, 각 Layer별로 넣을 수 있는 Function의 수와, 종류는 제한이 없다. 각 Layer마다 여러개의 Logistic function을 넣을 수 있다.
>
> 하지만, Logistic이 너무 많아질 경우, 계산이 너무 많아지고, 복잡해진다. 때문에 오히려 학습률이 떨어지는 결과를 초래한다.







## 종류

딥러닝이 발전하면서 여러가지로 세분화 되었다.

Deep learning    
-> CNN : 이미지 처리에 특화 (Converusion Neural Network)    
Deep learing     
-> RNN : 자연어 처리 (Recursive Neural Network)    
(자연어는 - 앞에 있는 단어에 뒤에 있는 단어에 영향을 끼친다.)

이렇게 두가지 알고리즘이 대표적인데, 다양한 알고리즘이 탄생하였고 지금도 생겨나고 있다.

- - -
지금도 계속 알고리즘이 생겨나고 있다.
이미지 처리도 지금은 CNN보다 좋은 알고리즘으로 GNN 등이 나타나고 있다.
이미지 처리를 잘 하기 위해서는 꼭 OpenCV를 같이 공부/사용 해야한다.
OpenCv는 이미지 처리에 특화 된 라이브러리

- - -
이번엔 CNN을 사용해서 MNIST를 학습시켜보자.

지금까지 우리가 한 학습은 Fully connected 네트워크이다. (모든 노드들이 연결되어 있었다.)    
CNN 또한 뒤쪽에 FC 단계가 있다. 하지만 CNN의 중요한 특징은 FC 앞쪽에 있는 새로운 계층들이다.    

CNN의 앞 부분은,    
이미지 전체를 학습하는 것이 아니라 이미지를 잘게 쪼개서, 각 부분들을 학습한다.    
그 잘게 쪼개진 이미지들을 학습하는 과정에서 이미지의 여러 ___특징___들이 학습된다.    

잘게 쪼개진 이미지들의 용량이 커버리면 전체 용량이 너무 커져버린다.
때문에 크기를 줄여줘야 원할한 학습이 가능해진다.    

- - -


## CNN

아래는 CNN에 사용되는 요소들이다.

### Filter

필터의 크기는 내가 마음대로 설정 할 수 있지만 Depth는 원본 이미지(3)와 같아야한다. -> 원본 이미지와 매칭해야 되기 때문    
Filter값을 정하고 Stride를 정하면 원본 이미지와 계산되어 몇개의 특징을 Node가 도출될지 계산된다.    



### Stride

Stride는 Image의 크기와 Filter값에 의해 가능한 숫자가 달라진다. (Default = 1) 
> ex>    
> 크기가 7 * 7 * 3 인 이미지가 있다. (depth가 3인 이유 : 이미지는 ( R, G, B ) 3개의 값이 1 pixel을 구성하기 때문)    
> 크기가 3 * 3 * 3 인 필터를 적용한다면, stride가 ~가 가능하다.    
> Stride가 Default인 1이라고 가정하면, 
> (image)7 * 7 * 3 -(filter : 3 * 3 * 3)-> (image)5 * 5 * 3 가 된다.

이렇게 필터를 한단계 더 적용하게 되면 이미지 크기가 3 * 3 * 3이 되는데, 이는 크기가 너무 작아서 특징을 추출하기 어려워진다.
그래서 __Padding__이 등장했다.



### Padding

그리고 이러한 특징들이 적용된 필터들을 하나의 계층에서도 여러개 만들 수 있다는 것이다.    
그렇게 되면 점점 더 많은 필터들이 중첩되기 시작한다.
> ex>
> 첫 이미지    CONV, ReLU    Layer 1
>  32x32x3   --(5x5x3, 6)--> 28x28x6

이런식으로 진행되면 최종적으로,
이미지의 크기는 줄어들지만 훨씬 더 많은 특징들을 학습 하게 된다.



### multi filter

여러개의 필터를 적용함으로써, 한 layer에서도 여러개의 필터를 적용 할 수 있다.
덕분에 Depth 가 점점 더 깊어지게 된다.



### Pooling (Max pooling)

이건 특징을 추출할수록 이미지의 크기가 너무 커져서, 특징은 유지하며 이미지 크기를 줄이는 단계이다.
여기는 필터와 비슷한 개념인 커널을 사용한다.
커널이 필터와 같이 stride값에 따라, 이미지를 부분 부분으로 자르면서 가장 큰 값의 특징을 추출한다.
그 덕분에 커널의 크기와 Stride 값에 따라 이미지의 특징을 잘 유지하면서도 이미지의 크기를 줄인 이미지를 만들 수 있다.

Pooling은 이미지 크기를 조정 하고 싶을 때, 언제든 사용 할 수 있다.
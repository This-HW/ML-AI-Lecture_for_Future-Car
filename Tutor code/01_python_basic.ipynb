{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Data\n",
    "# 일반적으로는 데이터 크기가 큰 데이터\n",
    "\n",
    "# Big Data의 정의\n",
    "# 3V\n",
    "# Volumn(데이터의 양) => 데이터의 크기가 아주 큰 데이터\n",
    "# Varietry(다양성) => 데이터의 다양성\n",
    "# Velocity(속도) => 데이터 발생 속도\n",
    "\n",
    "# 빅데이터 분석\n",
    "# EDA(탐색적 데이터 분석) => 데이터 분석의 가장 기본\n",
    "# 통계적 가설 검증(statistical hypothesis testing)\n",
    "\n",
    "# Machine Learning => prediction\n",
    "# deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      "x\n",
      "s is\n",
      "나는 사과를 100개 가지고 있어요!\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "[1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      "a가 10보다 커요!\n",
      "서울\n",
      "인천\n",
      "부산\n"
     ]
    }
   ],
   "source": [
    "# python의 주석은 # 으로 표현합니다!!\n",
    "\n",
    "# python의 사용되는 contant는 True, False, None\n",
    "# python은 weak type언어\n",
    "var1 = 3\n",
    "var2 = 3.14\n",
    "var3 = \"홍길동\"  \n",
    "# python은 문자개념이 없어요. 모두 문자열이예요!\n",
    "var4 = '홍길동'  # text sequence type\n",
    "var5 = True\n",
    "var6 = None\n",
    "var7 = \"this is a sample text\"\n",
    "# python은 배열이 없어요!\n",
    "print(var7[0])   # indexing\n",
    "print(var7[-2])\n",
    "# cell을 실행하려면 ctrl+enter하시면 되요!\n",
    "print(var7[3:7]) # slicing\n",
    "var8 = \"나는 사과를 {}개 가지고 있어요!\"\n",
    "print(var8.format(100))\n",
    "################## data type #################\n",
    "\n",
    "################## data structure ############\n",
    "# 1. list\n",
    "# [] 로 표현해요!\n",
    "list_1 = [1, 3.14, \"Hello\", True]\n",
    "# indexing과 slicing 사용 가능\n",
    "list_1 = [1,2,3]\n",
    "list_2 = [4,5,6]\n",
    "print(list_1 + list_2)  # list의 연결\n",
    "print(list_1 * 3)\n",
    "# 2. tuple\n",
    "# () 로 표현해요\n",
    "tuple_1 = (1,2,3,4,5)\n",
    "tuple_2 = (1,)  # 원소가 1개인 tuple\n",
    "tuple_3 = 1,2,3,4  # tuple은 ()를 생략할 수 있어요!\n",
    "# 3. range ( for문과 함께 사용되는게 일반적 )\n",
    "range_1 = range(10)\n",
    "range_2 = range(1,15,2)\n",
    "# 4. dictionary(dict) => hashmap, key와 value로 이루어진 자료구조\n",
    "# { }를 이용하여 key와 value의 쌍으로 데이터를 표현\n",
    "dict_1 = { \"name\" : \"홍길동\", \"age\" : 20, \"address\" : \"서울\"}\n",
    "# 5. set\n",
    "# { }를 이용해서 표현. key와 value로 표현하지 않아요!\n",
    "set_1 = {1,2,3,4,5}\n",
    "\n",
    "#######################################################\n",
    "\n",
    "# 제어문\n",
    "# if문\n",
    "# python은 제어문의 block을 표현할 때 {}를 이용하지 않아요!\n",
    "# indent를 이용해서 block을 표현.\n",
    "a = 20\n",
    "if a > 10:\n",
    "    print(\"a가 10보다 커요!\")\n",
    "elif a > 5:\n",
    "    print(\"a가 5보다 커요!\")\n",
    "else:\n",
    "    print(\"!!!!\")\n",
    "# for\n",
    "my_list = [\"서울\",\"인천\",\"부산\"]\n",
    "for tmp in my_list:\n",
    "    print(tmp)\n",
    "    \n",
    "## 내장함수, 사용자 정의 함수\n",
    "## 객체지향(class와 instance)\n",
    "## module & package\n",
    "###############################################\n",
    "\n",
    "# Data분석을 위해서 기본적으로 알아야 하는 library\n",
    "# Numpy : 수치계산을 위한 python library. Pandas의 기본 자료구조\n",
    "# Pandas : python에서 데이터분석을 위한 핵심 library\n",
    "# Matplotlib(seaborn) : 분석된 데이터를 그래프화 시키는 library\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1 2 3 4]\n",
      "[1.  2.  3.  4.1]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numpy =>  Numerical python\n",
    "# Vector와 matrix연산에 최적화\n",
    "# pandas와 matplotlib에서 사용되는 기본 자료구조\n",
    "# Numpy는 n-dimensional array => ndarray\n",
    "# ndarray는 배열이기 때문에 같은 데이터 타입만 사용가능\n",
    "import numpy as np\n",
    "\n",
    "a = [1,2,3,4]   # python의 list\n",
    "b = np.array([1,2,3,4])  # ndarray\n",
    "print(a)\n",
    "print(b)\n",
    "b = np.array([1,2,3.0,4.1])  # ndarray\n",
    "print(b)\n",
    "\n",
    "b = np.array([[1,2,3],[4,5,6]])\n",
    "print(b)\n",
    "\n",
    "b = np.array([[1,2,3],[4,5,6]], dtype=np.float64)\n",
    "print(b)\n",
    "\n",
    "print(b.shape)\n",
    "#############################\n",
    "# numpy를 이용한 난수발생\n",
    "# 1. 정규분포를 이용해서 난수를 발생\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정규분포 => 평균, 표준편차\n",
    "tmp_mean = 0\n",
    "tmp_std = 1 \n",
    "arr = np.random.normal(tmp_mean,tmp_std,(10000,))\n",
    "plt.hist(arr,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 균등분포 : [0,1)    \n",
    "arr = np.random.rand(1000000)\n",
    "plt.hist(arr,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[[100   1   2]\n",
      " [  3   4   5]\n",
      " [  6   7   8]\n",
      " [  9  10  11]]\n",
      "[100   1   2   3   4   5   6   7   8   9  10  11]\n"
     ]
    }
   ],
   "source": [
    "## ndarray는 형태를 마음대로 변형시킬 수 있어요!\n",
    "import numpy as np\n",
    "\n",
    "arr = np.arange(0,12,1)\n",
    "print(arr)   # 1차원의 ndarray\n",
    "\n",
    "arr1 = arr.reshape(4,3)\n",
    "print(arr1)  # 2차원의 ndarray로 변환이 되요!\n",
    "\n",
    "arr1[0,0] = 100   \n",
    "print(arr1)\n",
    "print(arr)\n",
    "## reshape()는 View를 만들어주는 역할."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([1,2,3])\n",
    "arr2 = np.array([4,5,6])\n",
    "\n",
    "print(arr1 * 3)  # broadcasting & vector연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 1]\n",
      " [7 1 7]]\n",
      "25\n",
      "[10 15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# seed값을 이용해서 난수의 재현성을 확보\n",
    "np.random.seed(11)\n",
    "# numpy는 집계함수를 제공\n",
    "arr = np.random.randint(0,10,(2,3))\n",
    "print(arr)\n",
    "print(arr.sum())   \n",
    "# axis에 대해서 알아보아요!\n",
    "# axis는 숫자값이예요.. 0,1,2,3,4,...\n",
    "# 차원에 따라서 사용할 수 있는 axis의 값이 제한, 의미가 달라져요\n",
    "\n",
    "# 1차원 ndarray [1 2 3 4 5]  axis = 0 => 열방향을 지칭\n",
    "# 2차원 ndarray axis=0 =>  행방향, axis=1 => 열방향\n",
    "print(arr.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>학과</th>\n",
       "      <th>학년</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>홍길동</td>\n",
       "      <td>수학</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>최길동</td>\n",
       "      <td>컴퓨터</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김길동</td>\n",
       "      <td>철학</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    이름   학과  학년\n",
       "0  홍길동   수학   1\n",
       "1  최길동  컴퓨터   3\n",
       "2  김길동   철학   4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pandas : python data 분석의 핵심 library (EDA)\n",
    "# pandas => 2개의 자료구조를 이용\n",
    "#           - Series    ( 1차원, ndarray의 vector구조 )\n",
    "#           - DataFrame ( 2차원, ndarray의 matrix구조)\n",
    "# 우리는 DataFrame을 이용해서 data처리를 해요!\n",
    "# 일반적으로 CSV파일이나, Database, OpenAPI같은 것들을 이용해서\n",
    "# 데이터를 DataFrame으로 로딩.\n",
    "import pandas as pd\n",
    "\n",
    "# dict(dictionary)를 이용해서 DataFrame을 만들어 보아요!\n",
    "data = {\"이름\" : [\"홍길동\",\"최길동\",\"김길동\"],\n",
    "        \"학과\" : [\"수학\",\"컴퓨터\",\"철학\"],\n",
    "        \"학년\" : [1, 3, 4]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine Learning\n",
    "\n",
    "### 1960년대부터 나온 개념.\n",
    "### explicit program으로 해결할 수 없는 문제를 해결하기 위해서 대두\n",
    "\n",
    "### 머신러닝을 구분하는 분류\n",
    "### 지도학습(Supervised Learning)\n",
    "###   - linear regression\n",
    "###   - logistic regression(binary classification)\n",
    "###   - multinomial classification\n",
    "### 비지도학습(Unsupervised Learning)\n",
    "### 강화학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear regression을 tensorflow를 이용해서 코드로\n",
    "## 구현해 보아요!\n",
    "\n",
    "## tesorflow는 google에서 지원하는 machine learning library\n",
    "## 기존의 library와는 사용법이 약간 달라요!\n",
    "\n",
    "## tensorflow는 graph를 그리는 library\n",
    "## tensorflow는 크게 3가지로 구성되어 있어요\n",
    "## 1. Node : 데이터의 입출력을 담당, 데이터의 연산을 담당\n",
    "## 2. edge : Node와 Node을 이어주는 선.\n",
    "## 3. tensor : 데이터를 나타내는 다차원배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(20, dtype=tf.float32)\n",
    "node2 = tf.constant(40, dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "# 그래프를 다 그렸으면 그래프를 실행시키는 runner가 필요\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run([node3,node1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.placeholder(dtype=tf.float32)\n",
    "node2 = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "# 그래프를 다 그렸으면 그래프를 실행시키는 runner가 필요\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(node3, feed_dict={node1 : 20,\n",
    "                                 node2 : 40}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 9.210203170776367\n",
      "cost값은 : 0.028821980580687523\n",
      "cost값은 : 0.00680086575448513\n",
      "cost값은 : 0.001604746445082128\n",
      "cost값은 : 0.00037865221383981407\n",
      "cost값은 : 8.934879588196054e-05\n",
      "cost값은 : 2.1083687897771597e-05\n",
      "cost값은 : 4.974469902663259e-06\n",
      "cost값은 : 1.1743763934646267e-06\n",
      "cost값은 : 2.776367580281658e-07\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [1,2,3]    # list로 해야되나요? ndarray로 하면 안되요?\n",
    "y_data = [3,5,7]\n",
    "\n",
    "# 2. placeholder\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# 3. Weight, bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "H = W * x + b\n",
    "\n",
    "# 5. cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.square(H-y))\n",
    "\n",
    "# 6. train\n",
    "# cost값을 줄이기 위해서 알고리즘을 이용(GradientDescent)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 7. sess, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(3000):\n",
    "    tmp_train, cost_val = sess.run([train,cost], \n",
    "                                   feed_dict={x:x_data,\n",
    "                                              y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.994705]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "print(sess.run(H, feed_dict={x:20}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 20447.0703125\n",
      "cost값은 : 1.8660732507705688\n",
      "cost값은 : 1.8634620904922485\n",
      "cost값은 : 1.8608849048614502\n",
      "cost값은 : 1.8583095073699951\n",
      "cost값은 : 1.8557332754135132\n",
      "cost값은 : 1.853137731552124\n",
      "cost값은 : 1.850563645362854\n",
      "cost값은 : 1.8480457067489624\n",
      "cost값은 : 1.8454668521881104\n"
     ]
    }
   ],
   "source": [
    "# machine learning \n",
    "# -> supervised learning(지도학습)\n",
    "#    Simple linear regression(단순 선형 회귀)\n",
    "#    Multiple linear regression(다중 선형 회귀)\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [[73,80,75],\n",
    "          [93,88,93],\n",
    "          [89,91,90],\n",
    "          [96,98,100],\n",
    "          [73,66,70]]\n",
    "y_data = [[152],[185],[180],[196],[142]]\n",
    "\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "H = tf.matmul(X,W) + b\n",
    "\n",
    "# 5. cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.000001).minimize(cost)\n",
    "\n",
    "# 7. session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(3000):\n",
    "    tmp_train, cost_val = sess.run([train,cost],\n",
    "                                  feed_dict={X:x_data,\n",
    "                                             Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 2.523132562637329\n",
      "cost값은 : 0.01573658548295498\n",
      "cost값은 : 0.015540690161287785\n",
      "cost값은 : 0.015511657111346722\n",
      "cost값은 : 0.015507194213569164\n",
      "cost값은 : 0.015506508760154247\n",
      "cost값은 : 0.015506403520703316\n",
      "cost값은 : 0.015506387688219547\n",
      "cost값은 : 0.015506384894251823\n",
      "cost값은 : 0.015506385825574398\n"
     ]
    }
   ],
   "source": [
    "## ozone data를 이용한 multiple linear regression 구현\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Data Loading & preprocessing(데이터 전처리)\n",
    "df = pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "# 결측치를 처리해야 해요!(NaN)\n",
    "# 결측치는 삭제하거나 다른 값으로 대체해서 처리해야 해요!\n",
    "df = df.dropna(how=\"any\")\n",
    "# 결측치를 처리한 후 이상치를 처리\n",
    "# 이상치를 찾아서 다른값으로 대체하거나 삭제하거나 하는 처리를\n",
    "# 해야해요!\n",
    "# 필요한 컬럼만 추출해보아요!\n",
    "df = df[[\"Ozone\",\"Solar.R\",\"Wind\",\"Temp\"]]\n",
    "# 학습이 가능한 형태로 만들기 위해서\n",
    "# 데이터를 normalization(정규화)시켜요!\n",
    "# 정규화된 값 = (현재값 - 최소값) / (최대값 - 최소값)\n",
    "# 일반적으로 sklearn package를 이용해서 편하게 처리\n",
    "scaler = MinMaxScaler()\n",
    "# 우리가 가진 데이터를 scaler를 이용해서 최대, 최소값을 구해서\n",
    "# scaling할 준비를 마쳐요!\n",
    "scaler.fit(df)\n",
    "data = scaler.transform(df)   # 최종 데이터 확보\n",
    "\n",
    "# 2. training data set\n",
    "x_data = data[:,1:]\n",
    "y_data = data[:,0].reshape(-1,1)\n",
    "\n",
    "# 3. placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "H = tf.matmul(X,W) + b\n",
    "\n",
    "# 5. cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 7. session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(3000):\n",
    "    tmp_train, cost_val = sess.run([train,cost],\n",
    "                                  feed_dict={X:x_data,\n",
    "                                             Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 0.8757730722427368\n",
      "cost 값은 : 0.44010502099990845\n",
      "cost 값은 : 0.3981914520263672\n",
      "cost 값은 : 0.36903899908065796\n",
      "cost 값은 : 0.346388041973114\n",
      "cost 값은 : 0.3281383812427521\n",
      "cost 값은 : 0.31309953331947327\n",
      "cost 값은 : 0.3004777431488037\n",
      "cost 값은 : 0.28971511125564575\n",
      "cost 값은 : 0.28040847182273865\n",
      "0.85714287\n",
      "[[0.75382835]]\n"
     ]
    }
   ],
   "source": [
    "## logistic regression(binary classification)\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set, test data set\n",
    "# 전체 100라인 데이터가 우리에게 제공됬으면\n",
    "# 7:3, 8:2 비율로 traing data와 test data를 분리해서 사용\n",
    "x_data = [[10,0],\n",
    "          [8,1],\n",
    "          [3,3],\n",
    "          [2,3],\n",
    "          [5,1],\n",
    "          [2,0],\n",
    "          [1,0]]\n",
    "y_data = [[1],[1],[1],[1],[0],[0],[0]]\n",
    "\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# 5. cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                             labels=Y))\n",
    "\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 7. session,초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(3000):\n",
    "    tmp_train, cost_val = sess.run([train,cost],\n",
    "                                  feed_dict={X:x_data,\n",
    "                                             Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))\n",
    "\n",
    "# 9. accuracy (정확도 측정)        \n",
    "# python에서  True, False => 1, 0 이렇게 변환이 가능\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "# H => [0.3, 0.7] => [False, True] => [0.,1.]\n",
    "correct = tf.equal(predict, Y)  # [True, False, True, ...]\n",
    "# [True, False, True, ...] => [1,0,1,...] => 평균\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:x_data,\n",
    "                              Y:y_data}))\n",
    "\n",
    "# 10. predict\n",
    "print(sess.run(H, feed_dict={X:[[3,2]]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression의 대표적인 예제(titanic)\n",
    "## kaggle의 예제를 통해서 학습해야 해요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 6.702394008636475\n",
      "cost 값은 : 0.5432921051979065\n",
      "cost 값은 : 0.46192726492881775\n",
      "cost 값은 : 0.4264044165611267\n",
      "cost 값은 : 0.4024551808834076\n",
      "cost 값은 : 0.38361451029777527\n",
      "cost 값은 : 0.3676656186580658\n",
      "cost 값은 : 0.3536169230937958\n",
      "cost 값은 : 0.3409445881843567\n",
      "cost 값은 : 0.3293393552303314\n",
      "[[7.2609341e-01 2.7379164e-01 1.1496954e-04]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## logistic 여러개를 모아놓은 multinomial classification을\n",
    "## 구현해 보아요!!\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set, test data set\n",
    "x_data = [[10,7,8,5],\n",
    "          [8,8,9,4],\n",
    "          [7,8,2,3],\n",
    "          [6,3,9,3],\n",
    "          [7,5,7,4],\n",
    "          [3,5,6,2],\n",
    "          [2,4,3,1]]\n",
    "y_data = [[1,0,0],\n",
    "          [1,0,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,0,1],\n",
    "          [0,0,1]]\n",
    "\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# 5. cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 7. session,초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(3000):\n",
    "    tmp_train, cost_val = sess.run([train,cost],\n",
    "                                  feed_dict={X:x_data,\n",
    "                                             Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))\n",
    "\n",
    "# prediction\n",
    "print(sess.run(H, feed_dict={X:[[10,8,9,4]]}))\n",
    "# 9. accuracy 측정\n",
    "predict = tf.argmax(H,axis=1)\n",
    "correct = tf.equal(predict,tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={X:x_data,\n",
    "                                    Y:y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost값은 : 1.1387383937835693\n",
      "cost값은 : 1.0957621335983276\n",
      "cost값은 : 0.8735387921333313\n",
      "cost값은 : 0.646654486656189\n",
      "cost값은 : 0.34171009063720703\n",
      "cost값은 : 0.3566572070121765\n",
      "cost값은 : 0.31542420387268066\n",
      "0.8965\n"
     ]
    }
   ],
   "source": [
    "## MNIST\n",
    "## Kaggle에도 data가 있고 tensorflow안에도 sample로 데이터가\n",
    "## 포함되어 있어요!\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data Loading & train data set, test data set\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session,초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "# epoch : 1 epoch은 traing data를 이용해서 1번 학습하는 것.\n",
    "train_epoch = 20\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        tmp_train, cost_val = sess.run([train,cost],\n",
    "                                       feed_dict={X:batch_x,\n",
    "                                                  Y:batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "# 정확도 측정\n",
    "predict = tf.argmax(H, axis=1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                    Y:mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 0.9101268649101257\n",
      "cost값은 : 0.7048580050468445\n",
      "cost값은 : 0.6939139366149902\n",
      "cost값은 : 0.6932116150856018\n",
      "cost값은 : 0.6931530833244324\n",
      "cost값은 : 0.6931477785110474\n",
      "cost값은 : 0.6931472420692444\n",
      "cost값은 : 0.6931471824645996\n",
      "cost값은 : 0.6931471824645996\n",
      "cost값은 : 0.6931471824645996\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "y_data = [[0], [1], [1], [0]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Wegiht & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                             labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    tmp_train, cost_val = sess.run([train,cost], \n",
    "                                   feed_dict={X:x_data,\n",
    "                                              Y:y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "\n",
    "# 정확도 측정\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:x_data,\n",
    "                                    Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 0.793597936630249\n",
      "cost값은 : 0.5934271216392517\n",
      "cost값은 : 0.4798058867454529\n",
      "cost값은 : 0.35167887806892395\n",
      "cost값은 : 0.24404899775981903\n",
      "cost값은 : 0.17017163336277008\n",
      "cost값은 : 0.1231633871793747\n",
      "cost값은 : 0.09309636056423187\n",
      "cost값은 : 0.07315230369567871\n",
      "cost값은 : 0.059350475668907166\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## NN을 이용한 XOR 구현\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 0. 그래프 전체를 초기화 해요!\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "y_data = [[0], [1], [1], [0]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Wegiht & bias\n",
    "W1 = tf.Variable(tf.random_normal([2,10]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), name=\"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,1]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), name=\"bias2\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer1,W2) + b2\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                             labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    tmp_train, cost_val = sess.run([train,cost], \n",
    "                                   feed_dict={X:x_data,\n",
    "                                              Y:y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "\n",
    "# 정확도 측정\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:x_data,\n",
    "                                    Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost값은 : 0.15703825652599335\n",
      "cost값은 : 0.08831323683261871\n",
      "cost값은 : 0.06189485639333725\n",
      "cost값은 : 0.05179793760180473\n",
      "cost값은 : 0.11505270004272461\n",
      "cost값은 : 0.010997005738317966\n",
      "cost값은 : 0.007938741706311703\n",
      "cost값은 : 0.0036909887567162514\n",
      "cost값은 : 0.07833801954984665\n",
      "cost값은 : 0.014533288776874542\n",
      "0.9751\n"
     ]
    }
   ],
   "source": [
    "## MNIST with deep learning\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading & train data set, test data set\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, rate=0.3)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,512],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate=0.3)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[512,10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2,W3) + b3\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# session,초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "# epoch : 1 epoch은 traing data를 이용해서 1번 학습하는 것.\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        tmp_train, cost_val = sess.run([train,cost],\n",
    "                                       feed_dict={X:batch_x,\n",
    "                                                  Y:batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "# 정확도 측정\n",
    "predict = tf.argmax(H, axis=1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                    Y:mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 사용하는 이미지는 (이미지개수,가로픽셀수,세로픽셀수,color)\n",
    "# (1,3,3,1)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype=np.float64)\n",
    "# 필터에 대한 정보(필터가로픽셀,필터세로픽셀,color,필터개수)\n",
    "# (2,2,1,3)\n",
    "weight = np.array([[[[1,10,-5]],[[1,10,-5]]],\n",
    "                   [[[1,10,-5]],[[1,10,-5]]]], dtype=np.float64)\n",
    "# stride = 1\n",
    "conv2d = tf.nn.conv2d(image,weight,strides=[1,1,1,1],\n",
    "                      padding=\"VALID\")\n",
    "print(conv2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(1, 26, 26, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD4CAYAAAAn+OBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQj0lEQVR4nO3dXWyWZZoH8P/fFhAoEUsBC7QMguiKyaIWswbdKJMlDhrqHMxkPBjYhCxzMJiZZEzWuAdj4oFkZcZMjJmks5phzKzjJDNED/wYJZMQT4xFEXC7a1FLoZTyUfmofAlce9CnSYN97+ul7/N+lOv/S5q27/Vw3xev/H3evs/d+6GZQUTiuK7aDYhIZSn0IsEo9CLBKPQiwSj0IsHUV3KyhoYGa2xsrOSUIqEMDg5iaGiIqWNKCj3JhwD8BkAdgP8ys82p4xsbG/HEE0+UMqWIJGzZssU9Ztwv70nWAXgRwPcA3A7gMZK3j3c8EamMUn6mvwfAPjP7wswuAPgTgPZ82hKRcikl9PMBHBj1/cHsMRGpYaWEfqw3C761ppfkRpKdJDuHhoZKmE5E8lBK6A8CaBn1/QIAh648yMw6zKzNzNoaGhpKmE5E8lBK6D8EcAvJRSQnA/gRgDfyaUtEymXcl+zM7CLJTQDewfAlu5fN7NPcOhORsijpOr2ZvQngzZx6EZEK0DJckWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFg6qvdgIytrq7OPWbGjBnJ+vHjx90xzCxZnzJlSrJ+4sQJdw7v7zJt2jR3DMlPSaEn2QPgNIBLAC6aWVseTYlI+eRxpn/QzI7lMI6IVIB+phcJptTQG4C/kdxJcuNYB5DcSLKTZOfQ0FCJ04lIqUp9eb/SzA6RnAPgXZL/a2Y7Rh9gZh0AOgCgtbU1/a6RiJRdSWd6MzuUfT4CYBuAe/JoSkTKZ9yhJzmd5IyRrwGsBrA3r8ZEpDxKeXk/F8A2kiPj/LeZvV1KM3lcmz5//nzJ83z11VfuGOXW29vrHrNkyZJkffLkye4Yg4ODyfrcuXNLnsNbL1DM8+29H9Tc3Jys19drScqIcT8TZvYFgH/MsRcRqQBdshMJRqEXCUahFwlGoRcJRqEXCUahFwlGoRcJpqIrFkgmF0lcvHjRHcNbfNPT0+OOsXDhwmTd2ziiEr7++mv3mL170wsgly1b5o6RLa4q6NSpU8n6HXfc4c5x7ty5ZH3SpEnuGO+9916yfujQoWR93rx57hxRFvDoTC8SjEIvEoxCLxKMQi8SjEIvEoxCLxKMQi8STEUvTJ4/fx6ff/55wfr06dPdMfr6+pL1gYEBdwzvmu7SpUvdMTyXLl1K1s+ePZusNzQ0uHN4G4p419gBf0MRb/OKzz77zJ1j1qxZyfq9997rjnHnnXcm6y+88EKy7v03B/xr+dfKdXyd6UWCUehFglHoRYJR6EWCUehFglHoRYJR6EWCoVnlbi9XX19vM2fOLFhftGiRO8bKlSuT9WKu9U+dOjVZz+N67A033FDSnz98+LB7TCWuG3s3oijm309ra2uy3tbW5o7h7Q1w3XXp89dzzz3nzuGtWWhqanLHqLYtW7agt7c3uUmCzvQiwSj0IsEo9CLBKPQiwSj0IsEo9CLBKPQiwSj0IsFUdFeA+vp6pBbnpDbYGPH4448n696NFQBgcHAwWfc2wCiGd8OMJUuWJOtz5sxx59i/f/9V9TQeJ06cSNZ37tzpjrFt27ZkfdOmTe4Yly9fTta9BT4bNmxw53j++eeT9YmwOKcY7pme5Mskj5DcO+qxRpLvkuzOPt9Y3jZFJC/FvLz/PYCHrnjsSQDbzewWANuz70VkAnBDb2Y7AFz5ergdwNbs660AHs25LxEpk/H+TD/XzPoBwMz6SRb8AZTkRgAbgWtnY0GRiazs796bWYeZtZlZm/dbTCJSfuMN/QDJZgDIPh/JryURKafxhv4NAOuzr9cDeD2fdkSk3Nwfskm+CuABAE0kDwL4JYDNAP5McgOAXgA/KGayWbNmYd26dQXr3vVzADhz5kyyPn/+fHcM7zr8N998447h8W4SsWvXrpLnqMR7JAsXLkzWb7zRv1rb0dGRrD/77LPuGJs3b07WvU007r//fneOBQsWuMdcC9x/NWb2WIHSd3PuRUQqQMtwRYJR6EWCUehFglHoRYJR6EWCUehFglHoRYKp6G/A1NXVJTfRSNVGXLhwIVn/8ssvr7ovGb9iFuesXbs2WX/xxRfdMd5///1k/ezZs8n6fffd586xYsWKZL2zszNZv/766905aoHO9CLBKPQiwSj0IsEo9CLBKPQiwSj0IsEo9CLBaKfKGkXSPWbSpEnJ+owZM9wxvA1Fjh07lqz39PS4c5hZsj558mR3jKNHjybr3t/D6wEAWlpakvXXXnstWV+2bJk7Ry3QmV4kGIVeJBiFXiQYhV4kGIVeJBiFXiQYhV4kGF2nLxPv5gvTpk1L1r3fDweAkydPJut9fX3uGN61ae8autcDAJw6dSpZX7NmjTuGt9eCt89CV1eXO8fSpUuT9ebmZneMiUBnepFgFHqRYBR6kWAUepFgFHqRYBR6kWAUepFgFHqRYLQ4ZwzeBhbewhrAXyziLVgp5qYd3sKY7u5ud4zW1tZk3dsYYvbs2e4c3gKfm2++2R3Dm8fbZOOTTz5x5/Bu3PHoo48m6zt27HDnqAXumZ7kyySPkNw76rGnSfaR3JV9+EuqRKQmFPPy/vcAHhrj8efNbHn28Wa+bYlIubihN7MdAAYr0IuIVEApb+RtIrk7e/lf8IchkhtJdpLsHBoaKmE6EcnDeEP/WwCLASwH0A/gV4UONLMOM2szs7aGhoZxTicieRlX6M1swMwumdllAL8DcE++bYlIuYwr9CRH/2Lx9wHsLXSsiNQW9zo9yVcBPACgieRBAL8E8ADJ5QAMQA+An5Sxx9zV16f/2lOmTEnWi7mG7m2C4V1jP3z4sDvH6dOnk/VVq1a5Y9TV1SXr3k0kVqxY4c6xe/fuZL2YDS4WLFiQrHv/TW+77TZ3jnPnziXrg4PXxvvZbujN7LExHn6pDL2ISAVoGa5IMAq9SDAKvUgwCr1IMAq9SDAKvUgwCr1IMCE30ejt7U3Wm5qakvW9e/0FiHv27EnWV65cmay3t7e7cxw5ciRZnz9/vjuGt/jm+PHjybq38QQArF69Ollft26dO4a3KcnixYuT9cbGRneOgYGBZN3bXGWi0JleJBiFXiQYhV4kGIVeJBiFXiQYhV4kGIVeJJiQ1+nfeeedZN27Juzd9AAA2trakvU5c+Yk68VcY7/11luT9WI2ffBuROFdmy5mzcKZM2eS9fPnz7tjeGsSWlpakvVZs2a5cxw8eDBZP3DggDvGRKAzvUgwCr1IMAq9SDAKvUgwCr1IMAq9SDAKvUgwIa/T33TTTcn622+/naw/88wz7hytra3Jundzhu7ubneOffv2ucfUgr6+vmTdzNwxZs6cmax76xq8tQKAvzfAiRMn3DEmAp3pRYJR6EWCUehFglHoRYJR6EWCUehFglHoRYJR6EWCCbk4Z9WqVcn63Llzk/X+/n53jtmzZyfrH3/8sTvGROBtwgH4i29OnTrljuFttHH33Xcn68eOHXPnOHfunHvMtcA905NsIfl3kl0kPyX5s+zxRpLvkuzOPvu3OhGRqivm5f1FAL8ws38A8E8AfkrydgBPAthuZrcA2J59LyI1zg29mfWb2UfZ16cBdAGYD6AdwNbssK0A/I3jRKTqruqNPJLfAXAngA8AzDWzfmD4fwwAxtzpkeRGkp0kO4eGhkrrVkRKVnToSTYA+AuAn5uZ/85Lxsw6zKzNzNoaGhrG06OI5Kio0JOchOHA/9HM/po9PECyOas3A0jvUSwiNaGYd+8J4CUAXWb261GlNwCsz75eD+D1/NsTkbwVc51+JYAfA9hDclf22FMANgP4M8kNAHoB/KA8LeZvypQpyfpdd92VrF+6dMmd41q5Du/54IMP3GMWL16crHs3/gCARYsWJetNTU3JuncDE2DibEpSKjf0ZvY+gEK3Ofluvu2ISLlpGa5IMAq9SDAKvUgwCr1IMAq9SDAKvUgwIX+fXopXV1eXrL/yyivuGA8//HCy3t7e7o6xdu3aZN3r0/t9fAAYGBhwj7kW6EwvEoxCLxKMQi8SjEIvEoxCLxKMQi8SjEIvEoxCLxKMFucEN7wxUmHeTSJaW1vdOfbv35+sewtvAGDq1KnJuvf36O7udueIQmd6kWAUepFgFHqRYBR6kWAUepFgFHqRYBR6kWB0nT4478Ydb731VrI+b948d44lS5Yk6w8++KA7xuXLl5P1rq6uZD3KBhnF0JleJBiFXiQYhV4kGIVeJBiFXiQYhV4kGIVeJBiFXiQYd3EOyRYAfwBwE4DLADrM7DcknwbwbwCOZoc+ZWZvlqtRKQ8zS9Z7enqS9aVLl7pzPPLII8m6twEGAJw8eTJZ37dvnzuGDCtmRd5FAL8ws49IzgCwk+S7We15M9tSvvZEJG9u6M2sH0B/9vVpkl0A5pe7MREpj6v6mZ7kdwDcCeCD7KFNJHeTfJnkjTn3JiJlUHToSTYA+AuAn5vZKQC/BbAYwHIMvxL4VYE/t5FkJ8nOoaGhHFoWkVIUFXqSkzAc+D+a2V8BwMwGzOySmV0G8DsA94z1Z82sw8zazKytoaEhr75FZJzc0HP4rdWXAHSZ2a9HPd486rDvA9ibf3sikrdi3r1fCeDHAPaQ3JU99hSAx0guB2AAegD8pCwdikiu6F2nzXUy8iiA0Xc+aAKQvptCbVCf+ZoIfU6EHoFv97nQzGan/kBFQ/+tyclOM2urWgNFUp/5mgh9ToQegfH1qWW4IsEo9CLBVDv0HVWev1jqM18Toc+J0CMwjj6r+jO9iFRetc/0IlJhCr1IMFULPcmHSP4fyX0kn6xWHx6SPST3kNxFsrPa/YzIfsnpCMm9ox5rJPkuye7sc1V/CapAj0+T7Muez10k11Szx6ynFpJ/J9lF8lOSP8ser7Xns1CfV/WcVuVnepJ1AD4D8C8ADgL4EMBjZvY/FW/GQbIHQJuZ1dRCDZL/DGAIwB/M7I7ssf8EMGhmm7P/kd5oZv9eYz0+DWColvZhyJaUN4/eMwLAowD+FbX1fBbq84e4iue0Wmf6ewDsM7MvzOwCgD8BaK9SLxOSme0AMHjFw+0AtmZfb8XwP4iqKdBjzTGzfjP7KPv6NICRPSNq7fks1OdVqVbo5wM4MOr7g6jdjTkMwN9I7iS5sdrNOOZmm56MbH4yp8r9FFKz+zBcsWdEzT6fpextUa3Qj7UpWq1eO1xpZncB+B6An2YvWWX8itqHoRrG2DOiJo13b4sR1Qr9QQAto75fAOBQlXpJMrND2ecjALahwL4BNWJg5Fees89HqtzPtxS7D0OljbVnBGrw+Sxlb4sR1Qr9hwBuIbmI5GQAPwLwRpV6KYjk9OwNE5CcDmA1anvfgDcArM++Xg/g9Sr2MqZa3Ieh0J4RqLHnM7e9LcysKh8A1mD4HfzPAfxHtfpwerwZwCfZx6e11CeAVzH8Uu4bDL9y2gBgFoDtALqzz4012OMrAPYA2I3hUDXXwHN5H4Z/vNwNYFf2saYGn89CfV7Vc6pluCLBaEWeSDAKvUgwCr1IMAq9SDAKvUgwCr1IMAq9SDD/D+pwBPnAgLaSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## MNIST 이미지를 이용해서 convolution layer 처리를 해 보아요!\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# plt.imshow(mnist.train.images[0].reshape(28,28), cmap=\"Greys\")\n",
    "# plt.show()\n",
    "# 사용하는 이미지는 (이미지개수,가로픽셀수,세로픽셀수,color)\n",
    "img = mnist.train.images[0].reshape(1,28,28,1)\n",
    "# 필터에 대한 정보(필터가로픽셀,필터세로픽셀,color,필터개수)\n",
    "w = tf.Variable(tf.random_normal([3,3,1,5]), name=\"filter1\")\n",
    "conv2d = tf.nn.conv2d(img,w,strides=[1,1,1,1],padding=\"VALID\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "\n",
    "plt.imshow(conv2d_img[4].reshape(26,26), cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 13, 13, 32)\n"
     ]
    }
   ],
   "source": [
    "## MNIST with CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# data loading, training data set, test data set\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# convolution layer\n",
    "# 사용하는 이미지는 (이미지개수,가로픽셀수,세로픽셀수,color)\n",
    "x_img = tf.reshape(X,[-1,28,28,1])\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32]), name=\"filter1\")\n",
    "L1 = tf.nn.conv2d(x_img,W1,strides=[1,1,1,1], padding=\"VALID\")\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1,2,2,1], strides=[1,2,2,1],\n",
    "                   padding=\"VALID\")\n",
    "print(L1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
